{"version":3,"file":"definitions.js","sourceRoot":"","sources":["../../src/definitions.ts"],"names":[],"mappings":"","sourcesContent":["export interface TextToSpeechPlugin {\n  /**\n   * Starts the TTS engine and plays the desired text.\n   */\n  speak(options: TTSOptions): Promise<void>;\n  /**\n   * Stops the TTS engine.\n   */\n  stop(): Promise<void>;\n  /**\n   * Returns a list of supported BCP 47 language tags.\n   */\n  getSupportedLanguages(): Promise<{ languages: string[] }>;\n  /**\n   * Returns a list of supported voices.\n   */\n  getSupportedVoices(): Promise<{ voices: SpeechSynthesisVoice[] }>;\n  /**\n   * Returns a list of supported voices.\n   */\n  getSupportedEngines(): Promise<{ engines: SpeechSynthesisEngine[] }>;\n\n  switchEngine(engineName: {engineName: string}): Promise<void>;\n\n  getDefaults(): Promise<{\n      engine: string,\n      voice: string,\n      language: string,\n  }>;\n  /**\n   * Checks if a specific BCP 47 language tag is supported.\n   */\n  isLanguageSupported(options: {\n    lang: string;\n  }): Promise<{ supported: boolean }>;\n  /**\n   * Verifies proper installation and availability of resource files on the system.\n   *\n   * Only available for Android.\n   */\n  openInstall(): Promise<void>;\n}\n\nexport interface TTSOptions {\n  /**\n   * The text that will be synthesised when the utterance is spoken.\n   *\n   * @example \"Hello world\"\n   */\n  text: string;\n  /**\n   * The language of the utterance.\n   * Possible languages can be queried using `getSupportedLanguages`.\n   *\n   * @default \"en-US\"\n   */\n  lang?: string;\n  /**\n   * The speed at which the utterance will be spoken at.\n   *\n   * @default 1.0\n   */\n  rate?: number;\n  /**\n   * The pitch at which the utterance will be spoken at.\n   *\n   * @default 1.0\n   */\n  pitch?: number;\n  /**\n   * The volume that the utterance will be spoken at.\n   *\n   * @default 1.0\n   */\n  volume?: number;\n  /**\n   * The index of the selected voice that will be used to speak the utterance.\n   * Possible voices can be queried using `getSupportedVoices`.\n   */\n  voice?: number;\n  /**\n   * Select the iOS Audio session category.\n   * Possible values: `ambient` and `playback`.\n   * Use `playback` to play audio even when the app is in the background.\n   *\n   * Only available for iOS.\n   *\n   * @default \"ambient\"\n   */\n  category?: string;\n}\n\n/**\n * The SpeechSynthesisVoice interface represents a voice that the system supports.\n */\nexport interface SpeechSynthesisVoice {\n  /**\n   * Specifies whether the voice is the default voice for the current app (`true`) or not (`false`).\n   *\n   * @example false\n   */\n  default: boolean;\n  /**\n   * BCP 47 language tag indicating the language of the voice.\n   *\n   * @example \"en-US\"\n   */\n  lang: string;\n  /**\n   * Specifies whether the voice is supplied by a local (`true`) or remote (`false`) speech synthesizer service.\n   *\n   * @example true\n   */\n  localService: boolean;\n  /**\n   * Human-readable name that represents the voice.\n   *\n   * @example \"Microsoft Zira Desktop - English (United States)\"\n   */\n  name: string;\n  /**\n   * Type of URI and location of the speech synthesis service for this voice.\n   *\n   * @example \"urn:moz-tts:sapi:Microsoft Zira Desktop - English (United States)?en-US\"\n   */\n  voiceURI: string;\n}\n\nexport interface SpeechSynthesisEngine {\n  icon: number;\n  label: string;\n  name: string;\n}\n"]}